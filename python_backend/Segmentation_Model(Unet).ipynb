{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f31a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45356b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,031,745</span> (118.38 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,031,745\u001b[0m (118.38 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4188s\u001b[0m 44s/step - accuracy: 0.7236 - loss: 0.4723 - val_accuracy: 0.7261 - val_loss: 0.3780\n",
      "Epoch 2/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3985s\u001b[0m 42s/step - accuracy: 0.6890 - loss: 1.2452 - val_accuracy: 0.7261 - val_loss: 0.5031\n",
      "Epoch 3/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4002s\u001b[0m 43s/step - accuracy: 0.7180 - loss: 0.4526 - val_accuracy: 0.7053 - val_loss: 0.2433\n",
      "Epoch 4/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23247s\u001b[0m 250s/step - accuracy: 0.7006 - loss: 0.2546 - val_accuracy: 0.7124 - val_loss: 0.2227\n",
      "Epoch 5/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3964s\u001b[0m 42s/step - accuracy: 0.7056 - loss: 0.2267 - val_accuracy: 0.7134 - val_loss: 0.2084\n",
      "Epoch 6/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3956s\u001b[0m 42s/step - accuracy: 0.7050 - loss: 0.2089 - val_accuracy: 0.7165 - val_loss: 0.2133\n",
      "Epoch 7/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4469s\u001b[0m 48s/step - accuracy: 0.7025 - loss: 0.2086 - val_accuracy: 0.7141 - val_loss: 0.1975\n",
      "Epoch 8/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3668s\u001b[0m 39s/step - accuracy: 0.7128 - loss: 0.1989 - val_accuracy: 0.7183 - val_loss: 0.1940\n",
      "Epoch 9/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3653s\u001b[0m 39s/step - accuracy: 0.7069 - loss: 0.1969 - val_accuracy: 0.7169 - val_loss: 0.1931\n",
      "Epoch 10/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4657s\u001b[0m 49s/step - accuracy: 0.7113 - loss: 0.1926 - val_accuracy: 0.7093 - val_loss: 0.1958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Conv2DTranspose, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "import tensorflow as tf\n",
    "\n",
    "# ================================\n",
    "# 1. Load Images and Masks\n",
    "# ================================\n",
    "def load_images_and_masks(image_folder, mask_folder, img_size):\n",
    "    images, masks = [], []\n",
    "\n",
    "    for filename in os.listdir(image_folder):\n",
    "        img_path = os.path.join(image_folder, filename)\n",
    "        mask_path = os.path.join(mask_folder, filename)\n",
    "\n",
    "        if os.path.exists(img_path) and os.path.exists(mask_path):\n",
    "            image = cv2.imread(img_path)\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            if image is not None and mask is not None:\n",
    "                image = cv2.resize(image, (img_size, img_size)) / 255.0\n",
    "                mask = cv2.resize(mask, (img_size, img_size)) / 255.0\n",
    "                mask = np.expand_dims(mask, axis=-1)\n",
    "\n",
    "                images.append(image)\n",
    "                masks.append(mask)\n",
    "            else:\n",
    "                print(f\"Failed to read {filename}\")\n",
    "\n",
    "    print(f\"Loaded {len(images)} images and {len(masks)} masks\")\n",
    "    return np.array(images), np.array(masks)\n",
    "\n",
    "# Paths to dataset\n",
    "image_folder = r'C:\\CINNAMON\\dataset\\image_folder'\n",
    "mask_folder = r'C:\\CINNAMON\\dataset\\masks_folder'\n",
    "img_size = 256\n",
    "\n",
    "# Load data\n",
    "X, y = load_images_and_masks(image_folder, mask_folder, img_size)\n",
    "\n",
    "# ================================\n",
    "# 2. Data Augmentation\n",
    "# ================================\n",
    "data_gen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "# Split into training and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ================================\n",
    "# 3. Dice Loss Function\n",
    "# ================================\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.0\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)\n",
    "    return 1 - (2.0 * intersection + smooth) / (union + smooth)\n",
    "\n",
    "# ================================\n",
    "# 4. Define U-Net Model\n",
    "# ================================\n",
    "def unet_model(input_shape, num_classes):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    p1 = Dropout(0.1)(p1)\n",
    "\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "    p2 = Dropout(0.1)(p2)\n",
    "\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    p3 = Dropout(0.2)(p3)\n",
    "\n",
    "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
    "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "    p4 = Dropout(0.2)(p4)\n",
    "\n",
    "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
    "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
    "    c5 = Dropout(0.3)(c5)\n",
    "\n",
    "    # Decoder\n",
    "    u6 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = Concatenate()([u6, c4])\n",
    "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
    "    c6 = Dropout(0.2)(c6)\n",
    "\n",
    "    u7 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = Concatenate()([u7, c3])\n",
    "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
    "    c7 = Dropout(0.2)(c7)\n",
    "\n",
    "    u8 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = Concatenate()([u8, c2])\n",
    "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
    "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
    "    c8 = Dropout(0.1)(c8)\n",
    "\n",
    "    u9 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = Concatenate()([u9, c1])\n",
    "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
    "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
    "    c9 = Dropout(0.1)(c9)\n",
    "\n",
    "    outputs = Conv2D(num_classes, (1, 1), activation='sigmoid')(c9)\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# ================================\n",
    "# 5. Compile and Train the Model\n",
    "# ================================\n",
    "input_shape = (img_size, img_size, 3)\n",
    "model = unet_model(input_shape, num_classes=1)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=ExponentialDecay(0.001, decay_steps=10000, decay_rate=0.9)),\n",
    "              loss=dice_loss,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n",
    "model_checkpoint = ModelCheckpoint('unet_cinnamon_segmentation.h5', save_best_only=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(data_gen.flow(X_train, y_train, batch_size=16),\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=50,\n",
    "                    callbacks=[early_stopping, reduce_lr, model_checkpoint])\n",
    "\n",
    "# ================================\n",
    "# 6. Save the Model\n",
    "# ================================\n",
    "model.save('unet_cinnamon_segmentation.h5')\n",
    "print(\"Model saved as 'unet_cinnamon_segmentation.h5'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f130171",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_val)\n",
    "# Ensure that y_val is binary\n",
    " #Threshold predictions to get binary masks\n",
    "y_pred_thresh = (y_pred > 0.5).astype(np.uint8)\n",
    "y_val_thresh = (y_val > 0.5).astype(np.uint8)\n",
    "\n",
    "# Flatten the arrays for metric calculation\n",
    "y_true_flat = y_val_thresh.flatten()\n",
    "y_pred_flat = y_pred_thresh.flatten()\n",
    "\n",
    "# Compute metrics\n",
    "precision = precision_score(y_true_flat, y_pred_flat)\n",
    "recall = recall_score(y_true_flat, y_pred_flat)\n",
    "f1 = f1_score(y_true_flat, y_pred_flat)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Dice Coefficient\n",
    "def dice_coefficient(y_true, y_pred, smooth=1):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    return (2. * intersection + smooth) / (np.sum(y_true) + np.sum(y_pred) + smooth)\n",
    "\n",
    "dice = dice_coefficient(y_val_thresh, y_pred_thresh)\n",
    "print(f\"Dice Coefficient: {dice:.4f}\")\n",
    "\n",
    "# Intersection over Union (IoU)\n",
    "def iou(y_true, y_pred):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred) - intersection\n",
    "    return intersection / union\n",
    "\n",
    "iou_score = iou(y_val_thresh, y_pred_thresh)\n",
    "print(f\"IoU: {iou_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65a783a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to preprocess image\n",
    "def preprocess_image(image_path, img_size):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (img_size, img_size)) / 255.0\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    return image\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('unet_cinnamon_segmentation.h5')\n",
    "\n",
    "# Path to the new image\n",
    "new_image_path = r'C:\\CINNAMON\\test_images\\test_image2.jpg'\n",
    "\n",
    "# Preprocess the new image\n",
    "img_size = 256  # Same size used during training\n",
    "new_image = preprocess_image(new_image_path, img_size)\n",
    "\n",
    "# Predict the mask\n",
    "predicted_mask = model.predict(new_image)\n",
    "\n",
    "# Threshold the predicted mask\n",
    "predicted_mask = (predicted_mask > 0.5).astype(np.uint8)\n",
    "\n",
    "# Remove the batch dimension\n",
    "predicted_mask = np.squeeze(predicted_mask)\n",
    "\n",
    "# Plot the original image and the predicted mask\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Original Image\n",
    "original_image = cv2.imread(new_image_path)\n",
    "original_image = cv2.resize(original_image, (img_size, img_size))\n",
    "ax[0].imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))\n",
    "ax[0].set_title('Original Image')\n",
    "ax[0].axis('off')\n",
    "\n",
    "# Predicted Mask\n",
    "ax[1].imshow(predicted_mask, cmap='gray')\n",
    "ax[1].set_title('Predicted Mask')\n",
    "ax[1].axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0419ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "\n",
    "\n",
    "# Function to preprocess image\n",
    "def preprocess_image(image_path, img_size):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (img_size, img_size)) / 255.0\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    return image\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('unet_cinnamon_segmentation.h5')\n",
    "\n",
    "# Path to the folder containing new images\n",
    "image_folder_path = r'C:\\CINNAMON\\test_images\\Test_images'\n",
    "img_size = 256  # Same size used during training\n",
    "\n",
    "# Process each image in the folder\n",
    "for image_file in os.listdir(image_folder_path):\n",
    "    image_path = os.path.join(image_folder_path, image_file)\n",
    "\n",
    "    # Preprocess the image\n",
    "    new_image = preprocess_image(image_path, img_size)\n",
    "\n",
    "    # Predict the mask\n",
    "    predicted_mask = model.predict(new_image)\n",
    "\n",
    "    # Threshold the predicted mask\n",
    "    predicted_mask = (predicted_mask > 0.5).astype(np.uint8)\n",
    "\n",
    "    # Remove the batch dimension\n",
    "    predicted_mask = np.squeeze(predicted_mask)\n",
    "\n",
    "    # Plot the original image and the predicted mask\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    # Original Image\n",
    "    original_image = cv2.imread(image_path)\n",
    "    original_image = cv2.resize(original_image, (img_size, img_size))\n",
    "    ax[0].imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))\n",
    "    ax[0].set_title('Original Image')\n",
    "    ax[0].axis('off')\n",
    "\n",
    "    # Predicted Mask\n",
    "    ax[1].imshow(predicted_mask, cmap='gray')\n",
    "    ax[1].set_title('Predicted Mask')\n",
    "    ax[1].axis('off')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fb6836-013e-44e0-a9af-69ffa8d35829",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
