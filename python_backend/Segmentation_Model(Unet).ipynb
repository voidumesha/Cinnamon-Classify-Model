{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37f31a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\cinnamon\\cinnamon app\\cinnamon app\\python_backend\\.venv\\lib\\site-packages (4.10.0.84)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\cinnamon\\cinnamon app\\cinnamon app\\python_backend\\.venv\\lib\\site-packages (from opencv-python) (2.0.2)\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f45356b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 369 images and 369 masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\CINNAMON\\Cinnamon App\\Cinnamon App\\python_backend\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55s/step - accuracy: 0.0014 - loss: 0.7892 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1216s\u001b[0m 63s/step - accuracy: 0.0014 - loss: 0.7889 - val_accuracy: 0.0000e+00 - val_loss: 0.7885 - learning_rate: 9.9980e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1047s\u001b[0m 54s/step - accuracy: 0.0000e+00 - loss: 0.7783 - val_accuracy: 0.0000e+00 - val_loss: 0.7885 - learning_rate: 9.9960e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1041s\u001b[0m 54s/step - accuracy: 0.0000e+00 - loss: 0.7760 - val_accuracy: 0.0000e+00 - val_loss: 0.7885 - learning_rate: 9.9940e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1034s\u001b[0m 54s/step - accuracy: 0.0000e+00 - loss: 0.7808 - val_accuracy: 0.0000e+00 - val_loss: 0.7885 - learning_rate: 9.9920e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1015s\u001b[0m 53s/step - accuracy: 0.0000e+00 - loss: 0.7836 - val_accuracy: 0.0000e+00 - val_loss: 0.7885 - learning_rate: 9.9900e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m 7/19\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m10:02\u001b[0m 50s/step - accuracy: 0.0000e+00 - loss: 0.7765"
     ]
    },
    {
     "ename": "AbortedError",
     "evalue": "Graph execution error:\n\nDetected at node StatefulPartitionedCall/functional_1/conv2d_9_1/Relu defined at (most recent call last):\n<stack traces unavailable>\nOperation received an exception:Status: 1, message: could not create a memory object, in file tensorflow/core/kernels/mkl/mkl_conv_ops.cc:1112\n\t [[{{node StatefulPartitionedCall/functional_1/conv2d_9_1/Relu}}]] [Op:__inference_multi_step_on_iterator_8720]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAbortedError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 148\u001b[0m\n\u001b[0;32m    145\u001b[0m model_checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munet_cinnamon_segmentation.h5\u001b[39m\u001b[38;5;124m'\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m--> 148\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_gen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# ================================\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;66;03m# 6. Save the Model\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m# ================================\u001b[39;00m\n\u001b[0;32m    156\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munet_cinnamon_segmentation.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\CINNAMON\\Cinnamon App\\Cinnamon App\\python_backend\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\CINNAMON\\Cinnamon App\\Cinnamon App\\python_backend\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mAbortedError\u001b[0m: Graph execution error:\n\nDetected at node StatefulPartitionedCall/functional_1/conv2d_9_1/Relu defined at (most recent call last):\n<stack traces unavailable>\nOperation received an exception:Status: 1, message: could not create a memory object, in file tensorflow/core/kernels/mkl/mkl_conv_ops.cc:1112\n\t [[{{node StatefulPartitionedCall/functional_1/conv2d_9_1/Relu}}]] [Op:__inference_multi_step_on_iterator_8720]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Conv2DTranspose, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "import tensorflow as tf\n",
    "\n",
    "# ================================\n",
    "# 1. Load Images and Masks\n",
    "# ================================\n",
    "def load_images_and_masks(image_folder, mask_folder, img_size):\n",
    "    images, masks = [], []\n",
    "\n",
    "    for filename in os.listdir(image_folder):\n",
    "        img_path = os.path.join(image_folder, filename)\n",
    "        mask_path = os.path.join(mask_folder, filename)\n",
    "\n",
    "        if os.path.exists(img_path) and os.path.exists(mask_path):\n",
    "            image = cv2.imread(img_path)\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            if image is not None and mask is not None:\n",
    "                image = cv2.resize(image, (img_size, img_size)) / 255.0\n",
    "                mask = cv2.resize(mask, (img_size, img_size)) / 255.0\n",
    "                mask = np.expand_dims(mask, axis=-1)\n",
    "\n",
    "                images.append(image)\n",
    "                masks.append(mask)\n",
    "            else:\n",
    "                print(f\"Failed to read {filename}\")\n",
    "\n",
    "    print(f\"Loaded {len(images)} images and {len(masks)} masks\")\n",
    "    return np.array(images), np.array(masks)\n",
    "\n",
    "# Paths to dataset\n",
    "image_folder = r'C:\\CINNAMON\\dataset\\image_folder'\n",
    "mask_folder = r'C:\\CINNAMON\\dataset\\masks_folder'\n",
    "img_size = 256\n",
    "\n",
    "# Load data\n",
    "X, y = load_images_and_masks(image_folder, mask_folder, img_size)\n",
    "\n",
    "# ================================\n",
    "# 2. Data Augmentation\n",
    "# ================================\n",
    "data_gen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "# Split into training and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ================================\n",
    "# 3. Dice Loss Function\n",
    "# ================================\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.0\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)\n",
    "    return 1 - (2.0 * intersection + smooth) / (union + smooth)\n",
    "\n",
    "# ================================\n",
    "# 4. Define U-Net Model\n",
    "# ================================\n",
    "def unet_model(input_shape, num_classes):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    p1 = Dropout(0.1)(p1)\n",
    "\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "    p2 = Dropout(0.1)(p2)\n",
    "\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    p3 = Dropout(0.2)(p3)\n",
    "\n",
    "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
    "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "    p4 = Dropout(0.2)(p4)\n",
    "\n",
    "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
    "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
    "    c5 = Dropout(0.3)(c5)\n",
    "\n",
    "    # Decoder\n",
    "    u6 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = Concatenate()([u6, c4])\n",
    "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
    "    c6 = Dropout(0.2)(c6)\n",
    "\n",
    "    u7 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = Concatenate()([u7, c3])\n",
    "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
    "    c7 = Dropout(0.2)(c7)\n",
    "\n",
    "    u8 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = Concatenate()([u8, c2])\n",
    "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
    "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
    "    c8 = Dropout(0.1)(c8)\n",
    "\n",
    "    u9 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = Concatenate()([u9, c1])\n",
    "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
    "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
    "    c9 = Dropout(0.1)(c9)\n",
    "\n",
    "    outputs = Conv2D(num_classes, (1, 1), activation='sigmoid')(c9)\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# ================================\n",
    "# 5. Compile and Train the Model\n",
    "# ================================\n",
    "input_shape = (img_size, img_size, 3)\n",
    "model = unet_model(input_shape, num_classes=1)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=ExponentialDecay(0.001, decay_steps=10000, decay_rate=0.9)),\n",
    "              loss=dice_loss,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n",
    "model_checkpoint = ModelCheckpoint('unet_cinnamon_segmentation.h5', save_best_only=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(data_gen.flow(X_train, y_train, batch_size=16),\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=50,\n",
    "                    callbacks=[early_stopping, reduce_lr, model_checkpoint])\n",
    "\n",
    "# ================================\n",
    "# 6. Save the Model\n",
    "# ================================\n",
    "model.save('unet_cinnamon_segmentation.h5')\n",
    "print(\"Model saved as 'unet_cinnamon_segmentation.h5'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f130171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 20s/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'precision_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m y_pred_flat \u001b[38;5;241m=\u001b[39m y_pred_thresh\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Compute metrics\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m precision \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_score\u001b[49m(y_true_flat, y_pred_flat)\n\u001b[0;32m     13\u001b[0m recall \u001b[38;5;241m=\u001b[39m recall_score(y_true_flat, y_pred_flat)\n\u001b[0;32m     14\u001b[0m f1 \u001b[38;5;241m=\u001b[39m f1_score(y_true_flat, y_pred_flat)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'precision_score' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_val)\n",
    "# Ensure that y_val is binary\n",
    " #Threshold predictions to get binary masks\n",
    "y_pred_thresh = (y_pred > 0.5).astype(np.uint8)\n",
    "y_val_thresh = (y_val > 0.5).astype(np.uint8)\n",
    "\n",
    "# Flatten the arrays for metric calculation\n",
    "y_true_flat = y_val_thresh.flatten()\n",
    "y_pred_flat = y_pred_thresh.flatten()\n",
    "\n",
    "# Compute metrics\n",
    "precision = precision_score(y_true_flat, y_pred_flat)\n",
    "recall = recall_score(y_true_flat, y_pred_flat)\n",
    "f1 = f1_score(y_true_flat, y_pred_flat)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Dice Coefficient\n",
    "def dice_coefficient(y_true, y_pred, smooth=1):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    return (2. * intersection + smooth) / (np.sum(y_true) + np.sum(y_pred) + smooth)\n",
    "\n",
    "dice = dice_coefficient(y_val_thresh, y_pred_thresh)\n",
    "print(f\"Dice Coefficient: {dice:.4f}\")\n",
    "\n",
    "# Intersection over Union (IoU)\n",
    "def iou(y_true, y_pred):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred) - intersection\n",
    "    return intersection / union\n",
    "\n",
    "iou_score = iou(y_val_thresh, y_pred_thresh)\n",
    "print(f\"IoU: {iou_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65a783a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to preprocess image\n",
    "def preprocess_image(image_path, img_size):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (img_size, img_size)) / 255.0\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    return image\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('unet_cinnamon_segmentation.h5')\n",
    "\n",
    "# Path to the new image\n",
    "new_image_path = r'C:\\CINNAMON\\test_images\\test_image2.jpg'\n",
    "\n",
    "# Preprocess the new image\n",
    "img_size = 256  # Same size used during training\n",
    "new_image = preprocess_image(new_image_path, img_size)\n",
    "\n",
    "# Predict the mask\n",
    "predicted_mask = model.predict(new_image)\n",
    "\n",
    "# Threshold the predicted mask\n",
    "predicted_mask = (predicted_mask > 0.5).astype(np.uint8)\n",
    "\n",
    "# Remove the batch dimension\n",
    "predicted_mask = np.squeeze(predicted_mask)\n",
    "\n",
    "# Plot the original image and the predicted mask\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Original Image\n",
    "original_image = cv2.imread(new_image_path)\n",
    "original_image = cv2.resize(original_image, (img_size, img_size))\n",
    "ax[0].imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))\n",
    "ax[0].set_title('Original Image')\n",
    "ax[0].axis('off')\n",
    "\n",
    "# Predicted Mask\n",
    "ax[1].imshow(predicted_mask, cmap='gray')\n",
    "ax[1].set_title('Predicted Mask')\n",
    "ax[1].axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0419ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "\n",
    "\n",
    "# Function to preprocess image\n",
    "def preprocess_image(image_path, img_size):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (img_size, img_size)) / 255.0\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    return image\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('unet_cinnamon_segmentation.h5')\n",
    "\n",
    "# Path to the folder containing new images\n",
    "image_folder_path = r'C:\\CINNAMON\\test_images\\Test_images'\n",
    "img_size = 256  # Same size used during training\n",
    "\n",
    "# Process each image in the folder\n",
    "for image_file in os.listdir(image_folder_path):\n",
    "    image_path = os.path.join(image_folder_path, image_file)\n",
    "\n",
    "    # Preprocess the image\n",
    "    new_image = preprocess_image(image_path, img_size)\n",
    "\n",
    "    # Predict the mask\n",
    "    predicted_mask = model.predict(new_image)\n",
    "\n",
    "    # Threshold the predicted mask\n",
    "    predicted_mask = (predicted_mask > 0.5).astype(np.uint8)\n",
    "\n",
    "    # Remove the batch dimension\n",
    "    predicted_mask = np.squeeze(predicted_mask)\n",
    "\n",
    "    # Plot the original image and the predicted mask\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    # Original Image\n",
    "    original_image = cv2.imread(image_path)\n",
    "    original_image = cv2.resize(original_image, (img_size, img_size))\n",
    "    ax[0].imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))\n",
    "    ax[0].set_title('Original Image')\n",
    "    ax[0].axis('off')\n",
    "\n",
    "    # Predicted Mask\n",
    "    ax[1].imshow(predicted_mask, cmap='gray')\n",
    "    ax[1].set_title('Predicted Mask')\n",
    "    ax[1].axis('off')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fb6836-013e-44e0-a9af-69ffa8d35829",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
